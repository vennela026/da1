{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "We start with an html element stored as a string in a variable"
      ],
      "metadata": {
        "id": "UD7fBq-Tk_sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bs4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onCCB9BRU1CV",
        "outputId": "b1e2f659-1c93-4eb3-901c-d25e728fa6b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bs4\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from bs4) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (2.6)\n",
            "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Installing collected packages: bs4\n",
            "Successfully installed bs4-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
      ],
      "metadata": {
        "id": "KZ7WS2G2OI3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Sample HTML document\n",
        "html_doc = \"\"\"\n",
        "<html>\n",
        "<head><title>World's Population</title></head>\n",
        "<body>\n",
        "    <h1>Main Heading</h1>\n",
        "    <p class=\"xyz\">This is a paragraph.</p>\n",
        "    <p class=\"content\">Another paragraph with <a href=\"https://example.com\">a link</a>.</p>\n",
        "\n",
        "    <div id=\"container\">\n",
        "        <ul>\n",
        "            <li class=\"item\">Item 1</li>\n",
        "            <li class=\"item\">Item 2</li>\n",
        "            <li class=\"item\">Item 3</li>\n",
        "        </ul>\n",
        "    </div>\n",
        "\n",
        "    <table>\n",
        "        <tr><th>Name</th><th>Age</th></tr>\n",
        "        <tr><td>Alice</td><td>25</td></tr>\n",
        "        <tr><td>Bob</td><td>30</td></tr>\n",
        "    </table>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "m8wg5az_WR8-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(html_doc, \"html.parser\")\n",
        "print(soup)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uK3_InNQYDs7",
        "outputId": "447ec824-685a-4ed4-dc21-a2e552d7d68f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "<html>\n",
            "<head><title>World's Population</title></head>\n",
            "<body>\n",
            "<h1>Main Heading</h1>\n",
            "<p class=\"xyz\">This is a paragraph.</p>\n",
            "<p class=\"content\">Another paragraph with <a href=\"https://example.com\">a link</a>.</p>\n",
            "<div id=\"container\">\n",
            "<ul>\n",
            "<li class=\"item\">Item 1</li>\n",
            "<li class=\"item\">Item 2</li>\n",
            "<li class=\"item\">Item 3</li>\n",
            "</ul>\n",
            "</div>\n",
            "<table>\n",
            "<tr><th>Name</th><th>Age</th></tr>\n",
            "<tr><td>Alice</td><td>25</td></tr>\n",
            "<tr><td>Bob</td><td>30</td></tr>\n",
            "</table>\n",
            "</body>\n",
            "</html>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding things via tags\n",
        "\n",
        "# 1. **Basic Parsing**\n",
        "print(\"Page Title:\", soup.body.text)  # Extract title\n",
        "#Limitation: Finds first occurence only"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uqks49G1XRTW",
        "outputId": "db2643a1-5853-41c1-e939-12c3052356e6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page Title: \n",
            "Main Heading\n",
            "This is a paragraph.\n",
            "Another paragraph with a link.\n",
            "\n",
            "\n",
            "Item 1\n",
            "Item 2\n",
            "Item 3\n",
            "\n",
            "\n",
            "\n",
            "NameAge\n",
            "Alice25\n",
            "Bob30\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. **Prettifying HTML Output**\n",
        "x = BeautifulSoup(\"<html><body><span>This is first</span><p>This is second</p></body></html>\",\"html.parser\")\n",
        "print(\"\\nPrettified HTML:\")\n",
        "print(x.prettify())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrFHHrjYFu10",
        "outputId": "dcaedb94-ede5-474c-cdbd-6b7063db9013"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prettified HTML:\n",
            "<html>\n",
            " <body>\n",
            "  <span>\n",
            "   This is first\n",
            "  </span>\n",
            "  <p>\n",
            "   This is second\n",
            "  </p>\n",
            " </body>\n",
            "</html>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. **Finding Elements**\n",
        "print(\"\\nFind first paragraph:\",( soup.find(\"p\").text) ) # First <p> tag\n",
        "print(\"Find all paragraphs:\", soup.find_all(\"p\"))  # All <p> tags\n",
        "x = []\n",
        "for i in soup.find_all(\"p\"):\n",
        "  x.append(i.text)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d90SVPtmXSWk",
        "outputId": "e0b1c405-682d-4e09-93a3-86d4a1304e22"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Find first paragraph: This is a paragraph.\n",
            "Find all paragraphs: [<p class=\"content\">This is a paragraph.</p>, <p class=\"content\">Another paragraph with <a href=\"https://example.com\">a link</a>.</p>]\n",
            "['This is a paragraph.', 'Another paragraph with a link.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2AofijstOGx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. **Using CSS Selectors**\n",
        "print(\"\\nUsing CSS Selectors:\")\n",
        "print(soup.select(\"p\")[0].text)  # Select by tag name\n",
        "print(soup.select(\".xyz\")[0].text)  # Select by class\n",
        "print(soup.select(\"#container ul li\")[1].text)  # Select second list item in <ul>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY65Swe5XS8S",
        "outputId": "f63e917a-cb7b-45e0-b8a3-75c59874bca9"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using CSS Selectors:\n",
            "This is a paragraph.\n",
            "This is a paragraph.\n",
            "Item 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. **Navigating the DOM**\n",
        "print(\"\\nNavigating the DOM:\")\n",
        "print(soup.body.h1.text)  # First <h1> tag inside <body>\n",
        "print(soup.body.div.ul.li.text)  # First <li> inside <div> -> <ul>"
      ],
      "metadata": {
        "id": "8U85mdtsXi_a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e333702-d0a0-4fcf-bfc5-70907064279a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Navigating the DOM:\n",
            "Main Heading\n",
            "Item 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. **Extracting Attributes**\n",
        "link = soup.find(\"a\")\n",
        "print(link.text)\n",
        "print(\"\\nExtracting Attributes:\")\n",
        "print(\"Link URL:\", link[\"href\"])  # Extract href attribute of <a>"
      ],
      "metadata": {
        "id": "NvuUgD_rXjuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 6. **Modifying HTML**\n",
        "print(\"\\nModifying HTML:\")\n",
        "soup.find(\"h1\").string = \"Updated Heading\"\n",
        "print(soup.h1.text)"
      ],
      "metadata": {
        "id": "lwI3L38tXjYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. **Extracting Text**\n",
        "print(\"\\nExtracting All Text from Page:\")\n",
        "print(soup.get_text(separator='|'))"
      ],
      "metadata": {
        "id": "G0fUVumfXwKl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4bf3c68-3d8c-46e8-f926-7f14b0e2cf37"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracting All Text from Page:\n",
            "\n",
            "|\n",
            "|Sample Webpage|\n",
            "|\n",
            "|Main Heading|\n",
            "|This is a paragraph.|\n",
            "|Another paragraph with |a link|.|\n",
            "|\n",
            "|\n",
            "|Item 1|\n",
            "|Item 2|\n",
            "|Item 3|\n",
            "|\n",
            "|\n",
            "|\n",
            "|Name|Age|\n",
            "|Alice|25|\n",
            "|Bob|30|\n",
            "|\n",
            "|\n",
            "|\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. **Decomposing (Removing) Elements**\n",
        "soup.find(\"h1\").decompose()  # Remove <h1> tag\n",
        "print(\"\\nAfter Removing h1:\", soup)"
      ],
      "metadata": {
        "id": "PASxBNavKQB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. **Working with Tables**\n",
        "table1 = soup.find(\"table\")\n",
        "rows = table1.find_all(\"tr\")\n",
        "print(\"\\nTable Data:\")\n",
        "for row in rows:\n",
        "   cols = row.find_all(\"td\")\n",
        "   print(row.text.split())\n",
        "   if cols:\n",
        "        print(f\"Name: {cols[0].text}, Age: {cols[1].text}\")"
      ],
      "metadata": {
        "id": "YrdhsmKkXwjS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "962f2967-f156-4dc1-8a3d-34218cb69c15"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Table Data:\n",
            "['NameAge']\n",
            "['Alice25']\n",
            "Name: Alice, Age: 25\n",
            "['Bob30']\n",
            "Name: Bob, Age: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsU7dSBMdJZ8"
      },
      "outputs": [],
      "source": [
        "x='<html><th>Location</th><th>Population</th></html>'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "eiSLsM_ydzF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(x))"
      ],
      "metadata": {
        "id": "Un-YPOBXlJCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Beautiful Soup, provided it's already installed"
      ],
      "metadata": {
        "id": "bOKC3RjHlPc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "TfgZZqBgd1CJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup=BeautifulSoup(x)\n",
        "print(soup)\n",
        "print(type(soup))"
      ],
      "metadata": {
        "id": "hhRV4B1heAGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding First Occurence, soup.find is helping us find the first occurence"
      ],
      "metadata": {
        "id": "aUxRyKTLe5pV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "firstfind = soup.find('th')\n",
        "print(firstfind)\n",
        "print(type(firstfind))\n",
        "print(firstfind.text)\n",
        "print(type(firstfind.text))"
      ],
      "metadata": {
        "id": "7PPzz4TheV44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding All occurences, soup.find_all is helping us find all occurences"
      ],
      "metadata": {
        "id": "0uxBcB0mfBeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "allfind=soup.find_all('th')\n",
        "print(allfind)\n",
        "print(type(allfind))\n",
        "print(allfind.text)#Error\n",
        "print(type(allfind.text))#Error\n"
      ],
      "metadata": {
        "id": "EjFGDFu0fBHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in allfind:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "pDTU1I3Qf-H1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in allfind:\n",
        "  print(i.text)"
      ],
      "metadata": {
        "id": "9VPKSDtOg12h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headers=[]\n",
        "for i in allfind:\n",
        "  headers.append(i.text)\n",
        "\n",
        "headers"
      ],
      "metadata": {
        "id": "Mm67SAHshK-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By List Comprehension"
      ],
      "metadata": {
        "id": "SaHeFKQ6h1SM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "headers = [i.text for i in allfind]\n",
        "headers"
      ],
      "metadata": {
        "id": "8nf0ck5ChsHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6VPz__6gioZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce9d7d3d"
      },
      "source": [
        "\n",
        "# Beautiful Soup Quiz - Code Tracing\n",
        "\n",
        "This notebook contains 10 questions focused on code tracing for Beautiful Soup. Each question includes code snippets, multiple-choice options, and the correct answer. Run the cells to see the correct answers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e60060c"
      },
      "source": [
        "### Question 1\n",
        "```python\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html_doc = \"<html><body><h1>Hello, World!</h1></body></html>\"\n",
        "soup = BeautifulSoup(html_doc, \"html.parser\")\n",
        "print(soup.h1.text)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "104aca6c"
      },
      "source": [
        "**Options:**\n",
        "A) <h1>Hello, World!</h1>\n",
        "B) Hello, World!\n",
        "C) None\n",
        "D) Error: AttributeError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09ad8bb5"
      },
      "outputs": [],
      "source": [
        "# Correct Answer\n",
        "print(\"Correct Answer: B) Hello, World!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2b53db3"
      },
      "source": [
        "### Question 2\n",
        "```python\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html_doc = \"<html><body><p class='info'>Python</p><p>Beautiful Soup</p></body></html>\"\n",
        "soup = BeautifulSoup(html_doc, \"html.parser\")\n",
        "print(soup.find('p').text)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "629bc6da"
      },
      "source": [
        "**Options:**\n",
        "A) Python\n",
        "B) Beautiful Soup\n",
        "C) <p class='info'>Python</p>\n",
        "D) None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fe73949"
      },
      "outputs": [],
      "source": [
        "# Correct Answer\n",
        "print(\"Correct Answer: A) Python\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55d6a4e1"
      },
      "source": [
        "### Question 3\n",
        "```python\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html_doc = \"\"\"\n",
        "<html>\n",
        "  <body>\n",
        "    <p class='content'>Paragraph 1</p>\n",
        "    <p>Paragraph 2</p>\n",
        "    <p class='content'>Paragraph 3</p>\n",
        "  </body>\n",
        "</html>\n",
        "\"\"\"\n",
        "soup = BeautifulSoup(html_doc, \"html.parser\")\n",
        "result = soup.find_all('p', class_='content')\n",
        "for item in result:\n",
        "    print(item.text)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f37b1798"
      },
      "source": [
        "**Options:**\n",
        "A) Paragraph 1\n",
        "B) Paragraph 1 and Paragraph 3\n",
        "C) Paragraph 2\n",
        "D) None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b714eb82"
      },
      "outputs": [],
      "source": [
        "# Correct Answer\n",
        "print(\"Correct Answer: B) Paragraph 1 and Paragraph 3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97fe9ee2"
      },
      "source": [
        "### Question 4\n",
        "```python\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html_doc = \"<html><a href='https://example.com'>Visit Example</a></html>\"\n",
        "soup = BeautifulSoup(html_doc, \"html.parser\")\n",
        "print(soup.a['href'])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8827e2fc"
      },
      "source": [
        "**Options:**\n",
        "A) https://example.com\n",
        "B) Visit Example\n",
        "C) <a href='https://example.com'>Visit Example</a>\n",
        "D) None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05bdd2df"
      },
      "outputs": [],
      "source": [
        "# Correct Answer\n",
        "print(\"Correct Answer: A) https://example.com\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50b131ba"
      },
      "source": [
        "### Question 5\n",
        "```python\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html_doc = \"\"\"\n",
        "<html>\n",
        "  <body>\n",
        "    <div>\n",
        "      <h1>Title</h1>\n",
        "      <p>Description</p>\n",
        "    </div>\n",
        "  </body>\n",
        "</html>\n",
        "\"\"\"\n",
        "soup = BeautifulSoup(html_doc, \"html.parser\")\n",
        "print(soup.div.h1.text)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "721f6bfd"
      },
      "source": [
        "**Options:**\n",
        "A) Title\n",
        "B) Description\n",
        "C) <h1>Title</h1>\n",
        "D) None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f99fd25e"
      },
      "outputs": [],
      "source": [
        "# Correct Answer\n",
        "print(\"Correct Answer: A) Title\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e29fbc8"
      },
      "source": [
        "### Question 6\n",
        "```python\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html_doc = \"\"\"\n",
        "<html>\n",
        "  <body>\n",
        "    <ul>\n",
        "      <li>Item 1</li>\n",
        "      <li>Item 2</li>\n",
        "      <li>Item 3</li>\n",
        "    </ul>\n",
        "  </body>\n",
        "</html>\n",
        "\"\"\"\n",
        "soup = BeautifulSoup(html_doc, \"html.parser\")\n",
        "items = soup.find_all('li')\n",
        "print(len(items))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3a449e3"
      },
      "source": [
        "**Options:**\n",
        "A) 1\n",
        "B) 2\n",
        "C) 3\n",
        "D) 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4360782a"
      },
      "outputs": [],
      "source": [
        "# Correct Answer\n",
        "print(\"Correct Answer: C) 3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "335fefa6"
      },
      "source": [
        "### Question 7\n",
        "```python\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html_doc = \"\"\"\n",
        "<html>\n",
        "  <body>\n",
        "    <div id=\"main\">\n",
        "      <p class=\"text\">First</p>\n",
        "      <p class=\"text\">Second</p>\n",
        "    </div>\n",
        "  </body>\n",
        "</html>\n",
        "\"\"\"\n",
        "soup = BeautifulSoup(html_doc, \"html.parser\")\n",
        "result = soup.select('#main .text')\n",
        "for item in result:\n",
        "    print(item.text)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e961a211"
      },
      "source": [
        "**Options:**\n",
        "A) First\n",
        "B) First and Second\n",
        "C) Second\n",
        "D) None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73bd8c6c"
      },
      "outputs": [],
      "source": [
        "# Correct Answer\n",
        "print(\"Correct Answer: B) First and Second\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5c0d418"
      },
      "source": [
        "### Question 8\n",
        "```python\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html_doc = \"<html><body><h1>Hello</h1><p>World</p></body></html>\"\n",
        "soup = BeautifulSoup(html_doc, \"html.parser\")\n",
        "print(soup.get_text())\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1164ef7c"
      },
      "source": [
        "**Options:**\n",
        "A) Hello World\n",
        "B) Hello\\nWorld\n",
        "C) <h1>Hello</h1><p>World</p>\n",
        "D) None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26a2dffc"
      },
      "outputs": [],
      "source": [
        "# Correct Answer\n",
        "print(\"Correct Answer: B) Hello\\nWorld\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cda67571"
      },
      "source": [
        "### Question 9\n",
        "```python\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html_doc = \"\"\"\n",
        "<html>\n",
        "  <body>\n",
        "    <img src=\"image1.png\" alt=\"First Image\">\n",
        "    <img src=\"image2.png\" alt=\"Second Image\">\n",
        "  </body>\n",
        "</html>\n",
        "\"\"\"\n",
        "soup = BeautifulSoup(html_doc, \"html.parser\")\n",
        "image = soup.find('img', alt='Second Image')\n",
        "print(image['src'])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94a11a3f"
      },
      "source": [
        "**Options:**\n",
        "A) image1.png\n",
        "B) image2.png\n",
        "C) <img src='image2.png' alt='Second Image'>\n",
        "D) None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b83bbd94"
      },
      "outputs": [],
      "source": [
        "# Correct Answer\n",
        "print(\"Correct Answer: B) image2.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d47ea62c"
      },
      "source": [
        "### Question 10\n",
        "```python\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html_doc = \"\"\"\n",
        "<html>\n",
        "  <body>\n",
        "    <p class=\"info detail\">Content 1</p>\n",
        "    <p class=\"info\">Content 2</p>\n",
        "  </body>\n",
        "</html>\n",
        "\"\"\"\n",
        "soup = BeautifulSoup(html_doc, \"html.parser\")\n",
        "result = soup.find_all('p', class_='info')\n",
        "for item in result:\n",
        "    print(item.text)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80caec56"
      },
      "source": [
        "**Options:**\n",
        "A) Content 1\n",
        "B) Content 2\n",
        "C) Content 1 and Content 2\n",
        "D) None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad440d0c"
      },
      "outputs": [],
      "source": [
        "# Correct Answer\n",
        "print(\"Correct Answer: C) Content 1 and Content 2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One Small Project**"
      ],
      "metadata": {
        "id": "zS1ug1trKUc2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beautiful Soup is a Python library used for web scraping purposes. It allows you to extract and manipulate data from HTML and XML documents. Here's an example to demonstrate how to use Beautiful Soup to scrape and process a webpage:\n",
        "\n",
        "**Example: Scraping Titles of Blog Posts**"
      ],
      "metadata": {
        "id": "eU0JqX2LKhm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "# URL of the webpage you want to scrape (using a real blog URL for example)\n",
        "url = 'https://realpython.com/'\n",
        "\n",
        "# Send an HTTP request to the webpage\n",
        "response = requests.get(url)\n",
        "\n",
        "# Parse the HTML content of the page\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Extract all the blog post titles (example: assuming titles are in <h2> tags with class 'card-title')\n",
        "titles = soup.find_all('h2', class_='card-title')\n",
        "\n",
        "# Print the extracted titles\n",
        "print(\"Blog Post Titles:\")\n",
        "for i, title in enumerate(titles, 1):\n",
        "    print(f\"{i}. {title.text.strip()}\")\n"
      ],
      "metadata": {
        "id": "nuQC8OhzM-lh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b4fe210-55eb-49db-c313-f96759709c6b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blog Post Titles:\n",
            "1. NumPy Techniques and Practical Examples\n",
            "2. Python for Loops: The Pythonic Way\n",
            "3. Top Python Game Engines\n",
            "4. Build a Quiz Application With Python\n",
            "5. Build a Dice-Rolling Application With Python\n",
            "6. Develop Data Visualization Interfaces in Python With Dash\n",
            "7. Build a Tic-Tac-Toe Game With Python and Tkinter\n",
            "8. Python & APIs: A Winning Combo for Reading Public Data\n",
            "9. Natural Language Processing With spaCy in Python\n",
            "10. Providing Multiple Constructors in Your Python Classes\n",
            "11. A Guide to Modern Python String Formatting Tools\n",
            "12. Split Your Dataset With scikit-learn's train_test_split()\n",
            "13. Creating a Scalable Flask Web Application From Scratch\n",
            "14. How to Split a Python List or Iterable Into Chunks\n",
            "15. Python's \"in\" and \"not in\" Operators: Check for Membership\n",
            "16. Lists vs Tuples in Python\n",
            "17. Python Folium: Create Web Maps From Your Data\n",
            "18. Python's Mutable vs Immutable Types: What's the Difference?\n",
            "19. Python's zipfile: Manipulate Your ZIP Files Efficiently\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Import Libraries\n",
        "The first step is to import the necessary libraries: BeautifulSoup for parsing the HTML content of the webpage and requests for making HTTP requests. These libraries allow us to retrieve the webpage and extract specific elements from its structure.\n",
        "\n",
        "Step 2: Specify the Target URL\n",
        "You define the URL of the webpage you want to scrape. In this project, the target is a blog site, such as \"https://realpython.com/\". This URL serves as the entry point for fetching the content that you want to analyze.\n",
        "\n",
        "Step 3: Send an HTTP Request\n",
        "An HTTP GET request is sent to the specified URL using the requests library. The server responds with the HTML content of the webpage, which we can then process. This step ensures you have access to the page's raw content.\n",
        "\n",
        "Step 4: Parse the HTML Content\n",
        "The HTML content from the response is passed to BeautifulSoup, which parses it and converts it into a structured format that can be navigated like a tree. This enables you to efficiently locate and extract specific elements (e.g., titles, links, or text) from the webpage.\n",
        "\n",
        "Step 5: Locate Blog Post Titles\n",
        "BeautifulSoup's find_all method is used to search for specific tags (e.g., <h2>) and their associated class attributes (e.g., class='card-title'). This method retrieves all the matching elements, which in this case are the blog post titles. The find_all function returns a list containing these elements.\n",
        "\n",
        "Step 6: Loop Through Titles\n",
        "The list of blog post titles is iterated using a loop. For each title, the text content is extracted using the .text attribute of the tag, and unnecessary whitespace is removed using the .strip() method. The loop prints each title alongside its position in the list.\n",
        "\n",
        "Step 7: Display the Extracted Titles\n",
        "Finally, the extracted blog titles are displayed as a numbered list. Each title is printed in a clean format, making it easy to see the output of the project. This step concludes the task, giving you a clear view of the blog posts retrieved from the webpage.\n",
        "\n",
        "This step-by-step process demonstrates the basic workflow of web scraping: accessing a webpage, parsing its structure, and extracting specific data in a meaningful way."
      ],
      "metadata": {
        "id": "UJTx2KEtN6Sj"
      }
    }
  ]
}